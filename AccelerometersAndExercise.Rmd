---
title: "How accelerometers, gyroscopes and magnetometers data can tell us whether people exercise correctly"
author: "Nathalie Descusse-Brown"
date: "April 04, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning=FALSE,message=FALSE)
```

## Executive Summary
This paper makes use of data from accelerometers, gyroscopes and magnetometers on the belt, forearm, arm, and dumbell of 6 participants. These participants were asked to perform barbell lifts correctly and incorrectly in 5 different ways. The aim of this paper is to use the data to predict the manner in which the participants  did the exercise. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).  

## Data Processing

The training dataset was accessed at the following site and assigned to the train tibble: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The testing dataset was accessed at the following site and assigned to the test tibble:
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv


```{r dataprocessing, cache=TRUE}
## load all data necessary to the assignment  
library(tidyverse)

if (!file.exists("pml-training.csv")) {
  fileUrl1 <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(fileUrl1,destfile="pml-training.csv")
fileUrl2 <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(fileUrl2,destfile="pml-testing.csv")
}
train <- read_csv("pml-training.csv")
test <- read_csv("pml-testing.csv")

```


## Exploratory Analysis

We know from the data source that the data is classified as follows:
- Class A: performed exactly according to the specification
- Class B: throwing the elbows to the front 
- Class C: lifting the dumbbell only halfway 
- Class D: lowering the dumbbell only halfway 
- Class E: throwing the hips to the front.

As there are 160 columns, the tibble train was first tidied up by removing the columns with a significant number of NA, empty, or #DIV/0! values. This leaves only 60 columns, which will significantly improve processing time. The first two columns of the train datasets were also removed as not necessary for model fitting. The test dataset was processed in a similar manner in view of making predictions.

```{r exploratoryanalysis}
library(plyr)
library(Hmisc)


tidytrain <- data.frame(stringsAsFactors=FALSE)
tidytest <- data.frame(stringsAsFactors=FALSE)

j <- 1
for (i in 1:dim(train)[2])
        {
                if (((count(is.na(train[,i]))[[1,2]]>11773) & (count(train[,i]=="")[[1,2]]>7849) & (count(train[,i]=="#DIV/0!")[[1,2]]>7849)) & length(tidytrain)==0)
                {
                        tidytrain <- train[,i]
                        tidytest <- test[,i]
                        # firstname <- colnames(train)[i]
                        j <- j+1
                }
                else if (((count(is.na(train[,i]))[[1,2]]>11773) & (count(train[,i]=="")[[1,2]]>7849) & (count(train[,i]=="#DIV/0!")[[1,2]]>7849)) & length(tidytrain)>0)
                {
                        tidytrain <- cbind(tidytrain,train[,i])
                        tidytest <- cbind(tidytest,test[,i])
                        colnames(tidytrain)[j] <- colnames(train)[i]
                        colnames(tidytest)[j] <- colnames(test)[i]
                        j <- j+1
                }
        }
        
tidytrain <- tidytrain[,-c(1,2)]
tidytest <- tidytest[,-c(1,2)]
```


Because of the classification and the location of the measuring devices we make the following assumptions:
- Class B should be associated with a negative gyros_dumbbell_z as the dumbell is pushed towards the shoulder when the elbow goes to the front.
- Class C should be associated with smaller gyros_dumbbell_y and gyros_forearm_y compared to Class A and Class B.
- Class D should be associated with similar amplitude gyros_dumbbell_y and gyros_forearm_y compared to Class C but shifted along the y axis.
- Class E should be associated with larger gyros_belt_z compared to other classes.


```{r ggpairexploratory, out.width = '1000px', dpi=300}

library(gridExtra) 

p = ggplot(tidytrain,aes(y=accel_dumbbell_z,x=accel_dumbbell_x,colour=classe))+geom_point(colour="grey50",size=0.5)+geom_point(size=0.5) + ylim(-2,2)
p2 = ggplot(tidytrain,aes(y=accel_dumbbell_y,x=accel_forearm_y,colour=classe))+geom_point(colour="pink",size=0.5)+
        geom_point(size=0.5) + ylim(-2,2)
p3 = ggplot(tidytrain,aes(y=accel_belt_z,x=accel_forearm_z,colour=classe))+geom_point(colour="pink",size=0.5)+
        geom_point(size=0.5) + ylim(-2,2)

grid.arrange(p,p2,p3,nrow=2, ncol=2)


```

We can see from the above that our assumptions were not verified as there is significant overlap (noise) between the data for the different classes. Owing to this and the fact that only a few of the covariates were considered in the exploratory analysis due to extend of the work required to look at all covariates, it was deemed more efficient to process with model selection.

## Model Selection and Results

Because no specific clusters were identified in the exploratory analysis, a random forest model was selected as it is known to be widely used and highly accurate without making any assumption as to the distribution of the data. However, speed was an issue when running the model at first. Some research into parallel processing led us to this very helpful guidance: https://github.com/lgreski/datasciencectacontent/blob/master/markdown/pml-randomForestPerformance.md. The computational speed was significantly improved by implementing parallel processing. The seeds argument of the trainControl function was also used to ensure reproducibility. Cross-validation was used as the training sample is relatively small with only 6 individuals.

```{r prediction}
library(caret)
library(rattle)
library(MASS)
library(parallel)
library(doParallel)

cluster <- makeCluster(detectCores() - 1) 
registerDoParallel(cluster)

seeds <- vector(mode = "list", length = 6)
for(i in 1:5) seeds[[i]]<- sample.int(n=1000, 3)
seeds[[6]] <- sample.int(1000, 1)

fitControl <- trainControl(method = "cv",
                            number = 5,
                            allowParallel = TRUE, seeds=seeds)

modelFit <- train(classe ~ .,method="rf",data=tidytrain,trControl = fitControl)

stopCluster(cluster)
registerDoSEQ()
print(modelFit)
modelFit$resample
confusionMatrix.train(modelFit)
```


## Discussion of the Model

The above results from the model show a very good accuracy and kappa for all 10 fold resamples. This means that the estimated out of sample error is very small so the model appears to be performing well.


## Predictions

Predictions were then made on new data and evaluated in a separate submission.

```{r predicting}
prediction <- predict(modelFit,newdata=tidytest[,-60])
```